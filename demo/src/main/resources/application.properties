spring.application.name=name_application
spring.cloud.stream.default-binder=kafka
spring.cloud.stream.default.contentType=text/plain
spring.cloud.stream.bindings.output-out-0.destination=topic1
spring.cloud.stream.bindings.output-out-0.producer.partition-count=3
spring.cloud.stream.kafka.bindings.output-in-0.producer.configuration.acks=all
spring.cloud.stream.bindings.gaaroutput-out-0.destination=topic2
spring.cloud.stream.bindings.gaaroutput-out-0.producer.partition-count=3
spring.cloud.stream.kafka.bindings.gaaroutput-in-0.producer.configuration.acks=all

spring.cloud.function.definition=input;outputconsumer
spring.cloud.stream.bindings.input-in-0.destination=topic1
spring.cloud.stream.bindings.input-in-0.group=${spring.application.name}
spring.cloud.stream.kafka.bindings.input-in-0.consumer.configuration.max.poll.interval.ms=30000
spring.cloud.stream.kafka.bindings.input-in-0.consumer.configuration.max.poll.records=1

#spring.cloud.stream.bindings.input-in-0.consumer.max-attempts=4
spring.cloud.stream.bindings.input-in-0.consumer.back-off-initial-interval=600000
spring.cloud.stream.bindings.input-in-0.consumer.back-off-max-interval=600000
spring.cloud.stream.bindings.input-in-0.consumer.back-off-multiplier=1.0
spring.cloud.stream.bindings.input-in-0.consumer.default-retryable=false
spring.cloud.stream.kafka.bindings.input-in-0.consumer.autoCommitOffset=false

spring.cloud.stream.kafka.bindings.input-in-0.consumer.enableDlq=true
spring.cloud.stream.kafka.bindings.input-in-0.consumer.dlqName=topic1-dlq
spring.cloud.stream.kafka.bindings.input-in-0.consumer.dlqPartitions=3

spring.cloud.stream.bindings.outputconsumer-in-0.destination=topic2
spring.cloud.stream.bindings.outputconsumer-in-0.group=${spring.application.name}
spring.cloud.stream.bindings.outputconsumer-in-0.consumer.max-attempts=1
spring.cloud.stream.kafka.bindings.outputconsumer-in-0.consumer.configuration.max.poll.interval.ms=30000
spring.cloud.stream.kafka.bindings.outputconsumer-in-0.consumer.configuration.max.poll.records=1

spring.cloud.stream.kafka.binder.producer-properties.acks=all
spring.cloud.stream.kafka.binder.auto-create-topics=false
spring.cloud.stream.kafka.binder.auto-add-partitions=false
spring.cloud.stream.kafka.default.consumer.startOffset=latest
spring.cloud.stream.kafka.default.producer.sync=true
spring.kafka.bootstrap-servers=locahost:9092

spring.kafka.jaas.enabled=true
spring.kafka.jaas.options.doNotPrompt=true
spring.kafka.jaas.options.useKeyTab=true
spring.kafka.jaas.options.storeKey=true
spring.kafka.properties.sasl.mechanism=GSSAPI
spring.kafka.properties.security.protocol=SASL_SSL
spring.kafka.jaas.options.keyTabEncoded=xyz
spring.kafka.jaas.options.principal=xyz
spring.kafka.properties.sasl.kerberos.service.name=kafka

java.security.krb5.confValue=[libdefaults]
default_realm = xyz.net
dns_lookup_realm = false
dns_lookup_kdc = false
ticket_lifetime = 24h
forwardable = true
udp_preference_limit = 1
default_tkt_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96 arc-four-hmac rc4-hmac
default_tgs_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96 arc-four-hmac rc4-hmac
permitted_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96 arc-four-hmac rc4-hmac

[realms]
INFOSOLCO.NET = {
kdc = adad.net:88
admin_server = adad.net:88
default_domain = xyz.net
}

[domain_realm]
.infosolco.net = xyz.net

infosolco.net = xyz.net